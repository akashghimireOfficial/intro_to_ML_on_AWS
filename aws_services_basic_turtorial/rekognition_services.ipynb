{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import os \n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.load_session import load_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "credential,session=load_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rekognition_client=session.client('rekognition')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some important methods in `rekognition_session`\n",
    "\n",
    "1. `.detect_labels()`: Detect objects,scenes, and concepts in an images. \n",
    "2. `.detect_faces()`: Detect faces in an image, and return bounding boxes,facial landmarks, and other facial attributes. \n",
    "3. `.detect_text()`: Detects text in an image\n",
    "4. `.detect_moderation_labels()`: Detects unsafe content in an image.  \n",
    "\n",
    "## Common and main parameters in above methods\n",
    "\n",
    "1.  ``Image``(**dict**): Specifies the input image is either as base64-encoded butes or as as S3 Object\n",
    "\n",
    "        Image have two **Sub-parameters**\n",
    "\n",
    "        `Bytes`(**bytes**): Image bytes object encoded as base 64 data. Must encode to bytes. \n",
    "\n",
    "        `S3Object` (dict): Image file store in S3 bucket. I takes two parameters again. a) `Bucket` (**string**), and `Name` (**String**) is `key`\n",
    "\n",
    "\n",
    "\n",
    "2. `MaxLabels`(**int**): Maximum number of labels to return. Controls how many labels you get in the response. ***Optional for `det_labels` method***\n",
    "\n",
    "3. `MinConfidence`(**float**): minimum confidence for consideration. \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying ``detect_labels``, and Image loading from S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading S3\n",
    "s3_client=session.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## seeing all the buckets \n",
    "bucket_names=[]\n",
    "bucket_lists=s3_client.list_buckets()\n",
    "\n",
    "for bucket in bucket_lists['Buckets']:\n",
    "    bucket_names.append(bucket['Name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_keys=[]\n",
    "for content in s3_client.list_objects_v2(Bucket=bucket_names[0],Prefix='images/')['Contents']:\n",
    "    img_keys.append(content['Key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['images/cars.png', 'images/emotion_faces.jpg']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_label=rekognition_client.detect_labels(\n",
    "    Image={\n",
    "        'S3Object': {\n",
    "            'Bucket': bucket_names[0],\n",
    "            'Name': img_keys[0]\n",
    "        }\n",
    "    \n",
    "    },\n",
    "\n",
    "    MinConfidence=50,\n",
    "    MaxLabels=10 \n",
    "\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Labels': [{'Name': 'Road',\n",
       "   'Confidence': 100.0,\n",
       "   'Instances': [],\n",
       "   'Parents': [],\n",
       "   'Aliases': [],\n",
       "   'Categories': [{'Name': 'Transport and Logistics'}]},\n",
       "  {'Name': 'Traffic Jam',\n",
       "   'Confidence': 93.18080139160156,\n",
       "   'Instances': [],\n",
       "   'Parents': [{'Name': 'Road'},\n",
       "    {'Name': 'Transportation'},\n",
       "    {'Name': 'Vehicle'}],\n",
       "   'Aliases': [],\n",
       "   'Categories': [{'Name': 'Vehicles and Automotive'}]},\n",
       "  {'Name': 'Vehicle',\n",
       "   'Confidence': 93.18080139160156,\n",
       "   'Instances': [],\n",
       "   'Parents': [{'Name': 'Transportation'}],\n",
       "   'Aliases': [],\n",
       "   'Categories': [{'Name': 'Vehicles and Automotive'}]},\n",
       "  {'Name': 'Outdoors',\n",
       "   'Confidence': 92.67257690429688,\n",
       "   'Instances': [],\n",
       "   'Parents': [],\n",
       "   'Aliases': [],\n",
       "   'Categories': [{'Name': 'Nature and Outdoors'}]},\n",
       "  {'Name': 'Car',\n",
       "   'Confidence': 86.66761016845703,\n",
       "   'Instances': [{'BoundingBox': {'Width': 0.19066843390464783,\n",
       "      'Height': 0.16686566174030304,\n",
       "      'Left': 2.5666826331871562e-05,\n",
       "      'Top': 0.8331332206726074},\n",
       "     'Confidence': 86.66761016845703},\n",
       "    {'BoundingBox': {'Width': 0.2520945370197296,\n",
       "      'Height': 0.17493152618408203,\n",
       "      'Left': 0.40012723207473755,\n",
       "      'Top': 0.8240493535995483},\n",
       "     'Confidence': 81.76095581054688},\n",
       "    {'BoundingBox': {'Width': 0.20709967613220215,\n",
       "      'Height': 0.28138667345046997,\n",
       "      'Left': 0.017306674271821976,\n",
       "      'Top': 0.5742427110671997},\n",
       "     'Confidence': 72.4007568359375},\n",
       "    {'BoundingBox': {'Width': 0.18782271444797516,\n",
       "      'Height': 0.24663567543029785,\n",
       "      'Left': 0.1120324581861496,\n",
       "      'Top': 0.4504101574420929},\n",
       "     'Confidence': 61.02580261230469}],\n",
       "   'Parents': [{'Name': 'Transportation'}, {'Name': 'Vehicle'}],\n",
       "   'Aliases': [{'Name': 'Automobile'}],\n",
       "   'Categories': [{'Name': 'Vehicles and Automotive'}]},\n",
       "  {'Name': 'License Plate',\n",
       "   'Confidence': 76.40982055664062,\n",
       "   'Instances': [{'BoundingBox': {'Width': 0.05288218334317207,\n",
       "      'Height': 0.022151613608002663,\n",
       "      'Left': 0.8331440091133118,\n",
       "      'Top': 0.5452149510383606},\n",
       "     'Confidence': 76.40982055664062},\n",
       "    {'BoundingBox': {'Width': 0.058193206787109375,\n",
       "      'Height': 0.02334607020020485,\n",
       "      'Left': 0.17601262032985687,\n",
       "      'Top': 0.5753059387207031},\n",
       "     'Confidence': 54.42485809326172},\n",
       "    {'BoundingBox': {'Width': 0.04891173914074898,\n",
       "      'Height': 0.02266778238117695,\n",
       "      'Left': 0.7622535824775696,\n",
       "      'Top': 0.4216855466365814},\n",
       "     'Confidence': 51.06121826171875}],\n",
       "   'Parents': [{'Name': 'Transportation'}, {'Name': 'Vehicle'}],\n",
       "   'Aliases': [],\n",
       "   'Categories': [{'Name': 'Vehicles and Automotive'}]},\n",
       "  {'Name': 'Moving Van',\n",
       "   'Confidence': 71.5215072631836,\n",
       "   'Instances': [{'BoundingBox': {'Width': 0.14630280435085297,\n",
       "      'Height': 0.2686886489391327,\n",
       "      'Left': 0.6677177548408508,\n",
       "      'Top': 0.005191049538552761},\n",
       "     'Confidence': 71.5215072631836},\n",
       "    {'BoundingBox': {'Width': 0.16652812063694,\n",
       "      'Height': 0.32291269302368164,\n",
       "      'Left': 0.17977799475193024,\n",
       "      'Top': 0.00842092465609312},\n",
       "     'Confidence': 68.1715316772461}],\n",
       "   'Parents': [{'Name': 'Transportation'},\n",
       "    {'Name': 'Van'},\n",
       "    {'Name': 'Vehicle'}],\n",
       "   'Aliases': [],\n",
       "   'Categories': [{'Name': 'Vehicles and Automotive'}]},\n",
       "  {'Name': 'Aerial View',\n",
       "   'Confidence': 56.984962463378906,\n",
       "   'Instances': [],\n",
       "   'Parents': [{'Name': 'Outdoors'}],\n",
       "   'Aliases': [],\n",
       "   'Categories': [{'Name': 'Colors and Visual Composition'}]},\n",
       "  {'Name': 'Freeway',\n",
       "   'Confidence': 53.43206024169922,\n",
       "   'Instances': [],\n",
       "   'Parents': [{'Name': 'Road'}],\n",
       "   'Aliases': [],\n",
       "   'Categories': [{'Name': 'Transport and Logistics'}]},\n",
       "  {'Name': 'Highway',\n",
       "   'Confidence': 52.23284912109375,\n",
       "   'Instances': [],\n",
       "   'Parents': [{'Name': 'Freeway'}, {'Name': 'Road'}],\n",
       "   'Aliases': [],\n",
       "   'Categories': [{'Name': 'Transport and Logistics'}]}],\n",
       " 'LabelModelVersion': '3.0',\n",
       " 'ResponseMetadata': {'RequestId': '4271cb75-db05-47d5-8472-61e66d37d203',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '4271cb75-db05-47d5-8472-61e66d37d203',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '3185',\n",
       "   'date': 'Sat, 13 Jul 2024 18:29:39 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels\n",
      "LabelModelVersion\n",
      "ResponseMetadata\n"
     ]
    }
   ],
   "source": [
    "for key in response_label.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying ``detect_labels``, and Image loading from local devices (Bytes Object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "with open('data/images/cars.png','rb') as image_file:\n",
    "    img_bytes=image_file.read()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_label=rekognition_client.detect_labels(\n",
    "    Image={\n",
    "        'Bytes':img_bytes\n",
    "    },\n",
    "    MaxLabels=10,\n",
    "    MinConfidence=75\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Labels': [{'Name': 'Road',\n",
       "   'Confidence': 100.0,\n",
       "   'Instances': [],\n",
       "   'Parents': [],\n",
       "   'Aliases': [],\n",
       "   'Categories': [{'Name': 'Transport and Logistics'}]},\n",
       "  {'Name': 'Traffic Jam',\n",
       "   'Confidence': 93.18080139160156,\n",
       "   'Instances': [],\n",
       "   'Parents': [{'Name': 'Road'},\n",
       "    {'Name': 'Transportation'},\n",
       "    {'Name': 'Vehicle'}],\n",
       "   'Aliases': [],\n",
       "   'Categories': [{'Name': 'Vehicles and Automotive'}]},\n",
       "  {'Name': 'Transportation',\n",
       "   'Confidence': 93.18080139160156,\n",
       "   'Instances': [],\n",
       "   'Parents': [],\n",
       "   'Aliases': [],\n",
       "   'Categories': [{'Name': 'Vehicles and Automotive'}]},\n",
       "  {'Name': 'Vehicle',\n",
       "   'Confidence': 93.18080139160156,\n",
       "   'Instances': [],\n",
       "   'Parents': [{'Name': 'Transportation'}],\n",
       "   'Aliases': [],\n",
       "   'Categories': [{'Name': 'Vehicles and Automotive'}]},\n",
       "  {'Name': 'Outdoors',\n",
       "   'Confidence': 92.67257690429688,\n",
       "   'Instances': [],\n",
       "   'Parents': [],\n",
       "   'Aliases': [],\n",
       "   'Categories': [{'Name': 'Nature and Outdoors'}]},\n",
       "  {'Name': 'Car',\n",
       "   'Confidence': 86.66761016845703,\n",
       "   'Instances': [{'BoundingBox': {'Width': 0.19066843390464783,\n",
       "      'Height': 0.16686566174030304,\n",
       "      'Left': 2.5666826331871562e-05,\n",
       "      'Top': 0.8331332206726074},\n",
       "     'Confidence': 86.66761016845703},\n",
       "    {'BoundingBox': {'Width': 0.2520945370197296,\n",
       "      'Height': 0.17493152618408203,\n",
       "      'Left': 0.40012723207473755,\n",
       "      'Top': 0.8240493535995483},\n",
       "     'Confidence': 81.76095581054688}],\n",
       "   'Parents': [{'Name': 'Transportation'}, {'Name': 'Vehicle'}],\n",
       "   'Aliases': [{'Name': 'Automobile'}],\n",
       "   'Categories': [{'Name': 'Vehicles and Automotive'}]},\n",
       "  {'Name': 'License Plate',\n",
       "   'Confidence': 76.40982055664062,\n",
       "   'Instances': [{'BoundingBox': {'Width': 0.05288218334317207,\n",
       "      'Height': 0.022151613608002663,\n",
       "      'Left': 0.8331440091133118,\n",
       "      'Top': 0.5452149510383606},\n",
       "     'Confidence': 76.40982055664062}],\n",
       "   'Parents': [{'Name': 'Transportation'}, {'Name': 'Vehicle'}],\n",
       "   'Aliases': [],\n",
       "   'Categories': [{'Name': 'Vehicles and Automotive'}]}],\n",
       " 'LabelModelVersion': '3.0',\n",
       " 'ResponseMetadata': {'RequestId': '1a3ec3e4-14cc-467a-99eb-5f31e300afc6',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '1a3ec3e4-14cc-467a-99eb-5f31e300afc6',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '1687',\n",
       "   'date': 'Sat, 13 Jul 2024 18:48:21 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .`detect_faces()` methods\n",
    "\n",
    "Other than common parameters it also take `Attributes` parameters\n",
    "\n",
    "About `Attributes` parameters: \n",
    "\n",
    "- Type: list of strings\n",
    "- Description: Specifies the facial attributes to return. The default is [``'DEFAULT'``], which returns basic attributes. [``'ALL'``] returns all available facial attributes.\n",
    "- Example: ['DEFAULT'] or ['ALL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_faces=rekognition_client.detect_faces(\n",
    "\n",
    "    Image={\n",
    "        'S3Object':\n",
    "        {\n",
    "            'Bucket':bucket_names[0],\n",
    "            'Name': img_keys[1]\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    \n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FaceDetails': [{'BoundingBox': {'Width': 0.16770029067993164,\n",
       "    'Height': 0.19006715714931488,\n",
       "    'Left': 0.716016411781311,\n",
       "    'Top': 0.045218780636787415},\n",
       "   'Landmarks': [{'Type': 'eyeLeft',\n",
       "     'X': 0.763200581073761,\n",
       "     'Y': 0.11629074811935425},\n",
       "    {'Type': 'eyeRight', 'X': 0.8328407406806946, 'Y': 0.11593988537788391},\n",
       "    {'Type': 'mouthLeft', 'X': 0.7706520557403564, 'Y': 0.1839667111635208},\n",
       "    {'Type': 'mouthRight', 'X': 0.8285028338432312, 'Y': 0.18366102874279022},\n",
       "    {'Type': 'nose', 'X': 0.7987505197525024, 'Y': 0.1471351534128189}],\n",
       "   'Pose': {'Roll': -0.8023471236228943,\n",
       "    'Yaw': -0.1536482721567154,\n",
       "    'Pitch': 11.169292449951172},\n",
       "   'Quality': {'Brightness': 91.77590942382812,\n",
       "    'Sharpness': 46.02980041503906},\n",
       "   'Confidence': 99.99625396728516},\n",
       "  {'BoundingBox': {'Width': 0.1697557419538498,\n",
       "    'Height': 0.17834661900997162,\n",
       "    'Left': 0.4123717248439789,\n",
       "    'Top': 0.04864475503563881},\n",
       "   'Landmarks': [{'Type': 'eyeLeft',\n",
       "     'X': 0.4617904722690582,\n",
       "     'Y': 0.1185457855463028},\n",
       "    {'Type': 'eyeRight', 'X': 0.5325372219085693, 'Y': 0.11797602474689484},\n",
       "    {'Type': 'mouthLeft', 'X': 0.46875277161598206, 'Y': 0.17956988513469696},\n",
       "    {'Type': 'mouthRight', 'X': 0.5278366208076477, 'Y': 0.17905694246292114},\n",
       "    {'Type': 'nose', 'X': 0.4995845854282379, 'Y': 0.15130028128623962}],\n",
       "   'Pose': {'Roll': -0.8026416897773743,\n",
       "    'Yaw': 1.3929450511932373,\n",
       "    'Pitch': 6.916254997253418},\n",
       "   'Quality': {'Brightness': 91.66661834716797,\n",
       "    'Sharpness': 46.02980041503906},\n",
       "   'Confidence': 99.99529266357422},\n",
       "  {'BoundingBox': {'Width': 0.17541103065013885,\n",
       "    'Height': 0.17222435772418976,\n",
       "    'Left': 0.10069503635168076,\n",
       "    'Top': 0.048182547092437744},\n",
       "   'Landmarks': [{'Type': 'eyeLeft',\n",
       "     'X': 0.15363557636737823,\n",
       "     'Y': 0.11634789407253265},\n",
       "    {'Type': 'eyeRight', 'X': 0.2262517511844635, 'Y': 0.11793668568134308},\n",
       "    {'Type': 'mouthLeft', 'X': 0.1584656536579132, 'Y': 0.17794917523860931},\n",
       "    {'Type': 'mouthRight', 'X': 0.21889722347259521, 'Y': 0.1792392134666443},\n",
       "    {'Type': 'nose', 'X': 0.18917779624462128, 'Y': 0.1444683074951172}],\n",
       "   'Pose': {'Roll': 0.2516299784183502,\n",
       "    'Yaw': 0.23321744799613953,\n",
       "    'Pitch': 13.333897590637207},\n",
       "   'Quality': {'Brightness': 92.16656494140625,\n",
       "    'Sharpness': 32.20803451538086},\n",
       "   'Confidence': 99.99764251708984},\n",
       "  {'BoundingBox': {'Width': 0.14083948731422424,\n",
       "    'Height': 0.17535558342933655,\n",
       "    'Left': 0.733343243598938,\n",
       "    'Top': 0.7227692008018494},\n",
       "   'Landmarks': [{'Type': 'eyeLeft',\n",
       "     'X': 0.7728455662727356,\n",
       "     'Y': 0.7807508707046509},\n",
       "    {'Type': 'eyeRight', 'X': 0.8369919061660767, 'Y': 0.7789731025695801},\n",
       "    {'Type': 'mouthLeft', 'X': 0.7811095118522644, 'Y': 0.8470339775085449},\n",
       "    {'Type': 'mouthRight', 'X': 0.8343837857246399, 'Y': 0.8455766439437866},\n",
       "    {'Type': 'nose', 'X': 0.8075687289237976, 'Y': 0.8064513802528381}],\n",
       "   'Pose': {'Roll': -1.4066096544265747,\n",
       "    'Yaw': 2.166537284851074,\n",
       "    'Pitch': 13.780055046081543},\n",
       "   'Quality': {'Brightness': 91.92833709716797,\n",
       "    'Sharpness': 53.330047607421875},\n",
       "   'Confidence': 99.99836730957031},\n",
       "  {'BoundingBox': {'Width': 0.12932033836841583,\n",
       "    'Height': 0.17282257974147797,\n",
       "    'Left': 0.7360464930534363,\n",
       "    'Top': 0.3868028521537781},\n",
       "   'Landmarks': [{'Type': 'eyeLeft',\n",
       "     'X': 0.7725916504859924,\n",
       "     'Y': 0.44764938950538635},\n",
       "    {'Type': 'eyeRight', 'X': 0.831331729888916, 'Y': 0.4473995864391327},\n",
       "    {'Type': 'mouthLeft', 'X': 0.7779606580734253, 'Y': 0.511992871761322},\n",
       "    {'Type': 'mouthRight', 'X': 0.8267415761947632, 'Y': 0.5118237137794495},\n",
       "    {'Type': 'nose', 'X': 0.8019008636474609, 'Y': 0.47755661606788635}],\n",
       "   'Pose': {'Roll': 0.23192724585533142,\n",
       "    'Yaw': 1.580054759979248,\n",
       "    'Pitch': 7.40169620513916},\n",
       "   'Quality': {'Brightness': 80.7667465209961, 'Sharpness': 46.02980041503906},\n",
       "   'Confidence': 99.9939193725586},\n",
       "  {'BoundingBox': {'Width': 0.14579515159130096,\n",
       "    'Height': 0.15289708971977234,\n",
       "    'Left': 0.41909465193748474,\n",
       "    'Top': 0.7245904803276062},\n",
       "   'Landmarks': [{'Type': 'eyeLeft',\n",
       "     'X': 0.4585084021091461,\n",
       "     'Y': 0.7821327447891235},\n",
       "    {'Type': 'eyeRight', 'X': 0.5238768458366394, 'Y': 0.7790609002113342},\n",
       "    {'Type': 'mouthLeft', 'X': 0.4671503007411957, 'Y': 0.8358213901519775},\n",
       "    {'Type': 'mouthRight', 'X': 0.5216189622879028, 'Y': 0.8332185745239258},\n",
       "    {'Type': 'nose', 'X': 0.49364548921585083, 'Y': 0.802762508392334}],\n",
       "   'Pose': {'Roll': -2.4355320930480957,\n",
       "    'Yaw': 0.5572361946105957,\n",
       "    'Pitch': 15.838604927062988},\n",
       "   'Quality': {'Brightness': 94.02977752685547,\n",
       "    'Sharpness': 38.89601135253906},\n",
       "   'Confidence': 99.99612426757812},\n",
       "  {'BoundingBox': {'Width': 0.140737384557724,\n",
       "    'Height': 0.1538175791501999,\n",
       "    'Left': 0.12053217738866806,\n",
       "    'Top': 0.7316791415214539},\n",
       "   'Landmarks': [{'Type': 'eyeLeft',\n",
       "     'X': 0.1588161736726761,\n",
       "     'Y': 0.7903957962989807},\n",
       "    {'Type': 'eyeRight', 'X': 0.22215934097766876, 'Y': 0.7876386642456055},\n",
       "    {'Type': 'mouthLeft', 'X': 0.16788418591022491, 'Y': 0.8454601764678955},\n",
       "    {'Type': 'mouthRight', 'X': 0.22056889533996582, 'Y': 0.843120813369751},\n",
       "    {'Type': 'nose', 'X': 0.193327859044075, 'Y': 0.8118026256561279}],\n",
       "   'Pose': {'Roll': -2.7304539680480957,\n",
       "    'Yaw': 1.4198954105377197,\n",
       "    'Pitch': 14.496236801147461},\n",
       "   'Quality': {'Brightness': 94.22671508789062,\n",
       "    'Sharpness': 32.20803451538086},\n",
       "   'Confidence': 99.99567413330078},\n",
       "  {'BoundingBox': {'Width': 0.12556524574756622,\n",
       "    'Height': 0.1481730043888092,\n",
       "    'Left': 0.42328327894210815,\n",
       "    'Top': 0.38636040687561035},\n",
       "   'Landmarks': [{'Type': 'eyeLeft',\n",
       "     'X': 0.4592856466770172,\n",
       "     'Y': 0.4424310028553009},\n",
       "    {'Type': 'eyeRight', 'X': 0.5169903039932251, 'Y': 0.4433054029941559},\n",
       "    {'Type': 'mouthLeft', 'X': 0.462686687707901, 'Y': 0.4945991635322571},\n",
       "    {'Type': 'mouthRight', 'X': 0.5108252763748169, 'Y': 0.4953232407569885},\n",
       "    {'Type': 'nose', 'X': 0.4881857931613922, 'Y': 0.4703676402568817}],\n",
       "   'Pose': {'Roll': 0.7123412489891052,\n",
       "    'Yaw': 0.6181756854057312,\n",
       "    'Pitch': 4.172717571258545},\n",
       "   'Quality': {'Brightness': 80.85211181640625, 'Sharpness': 26.1773681640625},\n",
       "   'Confidence': 99.98281860351562},\n",
       "  {'BoundingBox': {'Width': 0.12494459003210068,\n",
       "    'Height': 0.14575454592704773,\n",
       "    'Left': 0.12936869263648987,\n",
       "    'Top': 0.3929249346256256},\n",
       "   'Landmarks': [{'Type': 'eyeLeft',\n",
       "     'X': 0.164202019572258,\n",
       "     'Y': 0.448833167552948},\n",
       "    {'Type': 'eyeRight', 'X': 0.21982578933238983, 'Y': 0.4490140974521637},\n",
       "    {'Type': 'mouthLeft', 'X': 0.16896769404411316, 'Y': 0.5029220581054688},\n",
       "    {'Type': 'mouthRight', 'X': 0.21525903046131134, 'Y': 0.5030508041381836},\n",
       "    {'Type': 'nose', 'X': 0.19259169697761536, 'Y': 0.4767497479915619}],\n",
       "   'Pose': {'Roll': 0.41596218943595886,\n",
       "    'Yaw': 0.931657612323761,\n",
       "    'Pitch': 4.47932767868042},\n",
       "   'Quality': {'Brightness': 87.56710815429688,\n",
       "    'Sharpness': 20.927310943603516},\n",
       "   'Confidence': 99.97920227050781}],\n",
       " 'ResponseMetadata': {'RequestId': '14510d6b-e9f4-4dab-a650-d7da1490561c',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '14510d6b-e9f4-4dab-a650-d7da1490561c',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '5966',\n",
       "   'date': 'Sat, 13 Jul 2024 18:56:58 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BoundingBox': {'Width': 0.16770029067993164,\n",
       "  'Height': 0.19006715714931488,\n",
       "  'Left': 0.716016411781311,\n",
       "  'Top': 0.045218780636787415},\n",
       " 'Landmarks': [{'Type': 'eyeLeft',\n",
       "   'X': 0.763200581073761,\n",
       "   'Y': 0.11629074811935425},\n",
       "  {'Type': 'eyeRight', 'X': 0.8328407406806946, 'Y': 0.11593988537788391},\n",
       "  {'Type': 'mouthLeft', 'X': 0.7706520557403564, 'Y': 0.1839667111635208},\n",
       "  {'Type': 'mouthRight', 'X': 0.8285028338432312, 'Y': 0.18366102874279022},\n",
       "  {'Type': 'nose', 'X': 0.7987505197525024, 'Y': 0.1471351534128189}],\n",
       " 'Pose': {'Roll': -0.8023471236228943,\n",
       "  'Yaw': -0.1536482721567154,\n",
       "  'Pitch': 11.169292449951172},\n",
       " 'Quality': {'Brightness': 91.77590942382812, 'Sharpness': 46.02980041503906},\n",
       " 'Confidence': 99.99625396728516}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_faces['FaceDetails'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BoundingBox': {'Width': 0.1697557419538498,\n",
       "  'Height': 0.17834661900997162,\n",
       "  'Left': 0.4123717248439789,\n",
       "  'Top': 0.04864475503563881},\n",
       " 'Landmarks': [{'Type': 'eyeLeft',\n",
       "   'X': 0.4617904722690582,\n",
       "   'Y': 0.1185457855463028},\n",
       "  {'Type': 'eyeRight', 'X': 0.5325372219085693, 'Y': 0.11797602474689484},\n",
       "  {'Type': 'mouthLeft', 'X': 0.46875277161598206, 'Y': 0.17956988513469696},\n",
       "  {'Type': 'mouthRight', 'X': 0.5278366208076477, 'Y': 0.17905694246292114},\n",
       "  {'Type': 'nose', 'X': 0.4995845854282379, 'Y': 0.15130028128623962}],\n",
       " 'Pose': {'Roll': -0.8026416897773743,\n",
       "  'Yaw': 1.3929450511932373,\n",
       "  'Pitch': 6.916254997253418},\n",
       " 'Quality': {'Brightness': 91.66661834716797, 'Sharpness': 46.02980041503906},\n",
       " 'Confidence': 99.99529266357422}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_faces['FaceDetails'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
